{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:04:51.833127Z",
     "start_time": "2024-12-23T02:04:51.347405Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "filt = lambda x: '_' in x\n",
    "get_letter = lambda x: x.split('.')[0]\n",
    "#·for·i·in·range(10):\n",
    "letters = list(filter(filt,glob('*.npy')))\n",
    "letters= ['l0_ya.npy', 'l1_yu.npy', 'l2_oi.npy', 'l3_yoi.npy', 'l4_yai.npy', 'l5_p.npy',\n",
    "          'l6_m.npy', 'l7_t.npy', 'l8_r.npy', 'l9_b.npy',\n",
    "          'letsbuy.npy', 'letsgo.npy', 'letsride.npy', 'kick.npy','getout.npy']\n",
    "letters = letters[:10]\n",
    "ls = list(map(np.load, letters)) # letters[:10], letters[10:]\n",
    "d = dict(zip(list(map(get_letter,letters)),ls))\n",
    "d"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a03b562b040806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:04:54.941829Z",
     "start_time": "2024-12-23T02:04:54.832933Z"
    }
   },
   "source": [
    "letters = [ 'l0_ya.npy', 'l1_yu.npy', 'l2_oi.npy', 'l3_yoi.npy', 'l4_yai.npy',\n",
    "            'l5_p.npy', 'l6_m.npy', 'l7_t.npy', 'l8_r.npy', 'l9_b.npy']\n",
    "fig, ax = plt.subplots(len(letters)//2,2)\n",
    "ax = [a for ae in ax for a in ae]\n",
    "for i, lett in enumerate(letters):\n",
    "    ax[i].imshow(np.load(lett), cmap=plt.cm.Greens, clim=[-1,2])\n",
    "    ax[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.05,hspace=0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79f4bb05e4cd325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:04:57.371235Z",
     "start_time": "2024-12-23T02:04:57.226014Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "t = np.arange(6)\n",
    "plt.plot(t, np.cumsum(1 / 150 * np.exp(-t)), '-o')\n",
    "\n",
    "inp = np.array([1., 0., 1., 0., 1.])\n",
    "\n",
    "def output_row(initial_state, input_signal):\n",
    "    \"\"\"\n",
    "    This function emulates the behavior of a memristor PoC.\n",
    "    Insert here a more detailed model or integrate a differential equation\n",
    "    for better behavior.\n",
    "    Ideally the experimental data should be here.\n",
    "    Parameters\n",
    "    ----------\n",
    "    initial_state : conductance value before any pulse.\n",
    "    input_signal : signal of the applied pulses.\n",
    "    Returns\n",
    "    -------\n",
    "    a : the output of the conductance. this has to be extracted of the device.\n",
    "    \"\"\"\n",
    "    a = [initial_state]\n",
    "    for i in range(5):\n",
    "        if input_signal[i] > 0:\n",
    "            a.append(np.clip(a[i], 0.1, 1) * np.exp(1))\n",
    "        else:\n",
    "            a.append(np.clip(a[i], 1, 10) * (3 - np.exp(1)))\n",
    "    return np.array(a).flatten()  # 确保 output 为一维数组\n",
    "\n",
    "matrix = np.zeros((10, 31))\n",
    "nr = 0\n",
    "for nl, lett in enumerate(d.keys()):\n",
    "    print(nl, nr)\n",
    "    for nr, row in enumerate(d[lett]):\n",
    "        initial_state = np.random.random(1)\n",
    "        output = output_row(initial_state, row)\n",
    "\n",
    "        # 确保 output 与 matrix 的目标切片形状一致\n",
    "        if output.size >= 6:\n",
    "            ax[0].plot(output[:6] + np.random.random(1) * 1e-4, '-o')\n",
    "            matrix[nl, nr * 6:(nr + 1) * 6] = output[:6]\n",
    "        else:\n",
    "            print(f\"Warning: output size {output.size} is too small.\")\n",
    "\n",
    "matrix[:, 30] = 2.5 * np.random.random((10,))\n",
    "\n",
    "plt.figure()\n",
    "ax[1].imshow(matrix, extent=[10, 1, 1, 31], aspect='auto')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3ad89493c5a333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:05:17.515905Z",
     "start_time": "2024-12-23T02:05:17.509891Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "one hot encoding, softmax function activation and training procedure\n",
    "\"\"\"\n",
    "def one_hot(y, c):\n",
    "    \"\"\"\n",
    "    # y--> label/ground truth.\n",
    "    # c--> Number of classes.\n",
    "    \"\"\"\n",
    "    # A zero matrix of size (m, c)\n",
    "    y_hot = np.zeros((len(y), c))\n",
    "    # Putting 1 for column where the label is,\n",
    "    # Using multidimensional indexing.\n",
    "    y_hot[np.arange(len(y)), y] = 1\n",
    "    return y_hot\n",
    "\n",
    "one_hot([5,2,3], 10)\n",
    "\n",
    "def softmax(z):\n",
    "    # z--> linear part.\n",
    "    # subtracting the max of z for numerical stability.\n",
    "    exp = np.exp(z - np.max(z))\n",
    "    # Calculating softmax for all example letters.\n",
    "    for i in range(len(z)):\n",
    "        exp[i] /= np.sum(exp[i])\n",
    "    return exp\n",
    "\n",
    "# fit(X,np.arange(10),0.1,10,100)\n",
    "def fit(X, y, lr, c, epochs):\n",
    "    \"\"\"\n",
    "    # X --> Input.\n",
    "    # y --> true/target value.\n",
    "    # lr --> Learning rate.\n",
    "    # c --> Number of classes.\n",
    "    # epochs --> Number of iterations.\n",
    "    \"\"\"\n",
    "    # m-> number of training examples\n",
    "    # n-> number of features\n",
    "    m, n = X.shape\n",
    "    # Initializing weights and bias randomly.\n",
    "    w = np.random.random((n, c))\n",
    "    b = np.random.random(c)\n",
    "    # Empty list to store losses.\n",
    "    losses = []\n",
    "    # np.save('initial_w.npy',w)\n",
    "    # Training loop.\n",
    "    for epoch in range(epochs):\n",
    "        # Calculating hypothesis/prediction.\n",
    "        z = X@w + b\n",
    "        y_hat = softmax(z)\n",
    "        # One-hot encoding y.\n",
    "        y_hot = one_hot(y, c)\n",
    "        # Calculating the gradient of loss w.r.t w and b.\n",
    "        w_grad = (1/m)*np.dot(X.T, (y_hat - y_hot))\n",
    "        b_grad = (1/m)*np.sum(y_hat - y_hot)\n",
    "        # Updating the parameters.\n",
    "        w = w - lr*w_grad\n",
    "        b = b - lr*b_grad\n",
    "        # np.save('w' + str(epoch) + '.npy',w)\n",
    "        # Calculating loss and appending it in the list.\n",
    "        loss = -np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        losses.append(loss)\n",
    "        # Printing out the loss at every 100th iteration.\n",
    "        if epoch%1==0:\n",
    "            print('Epoch {epoch}==> Loss = {loss}'.format(epoch=epoch, loss=loss))\n",
    "    return w, b, losses"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc86525c6cab6a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:05:24.375666Z",
     "start_time": "2024-12-23T02:05:24.196118Z"
    }
   },
   "source": [
    "\"\"\" 10 examples for the training, each example has 6*5 features, or 30 virtual reservoir nod\n",
    "\"\"\"\n",
    "X = np.zeros((10,30))\n",
    "for i, letter in enumerate(d.keys()):\n",
    "    initial_state = np.random.random(1)\n",
    "    output = []\n",
    "    for row in d[letter]:\n",
    "        output.append(output_row(initial_state,row))\n",
    "    X[i,:] = np.concatenate(output)  # 去掉[:, 0]，直接赋值\n",
    "\n",
    "    \n",
    "w, b, losses = fit(X,np.arange(10),0.1,10,100)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50b125fa7990e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:05:38.393733Z",
     "start_time": "2024-12-23T02:05:37.756163Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "here I add noise in each position of the 25 positions of the matrix\n",
    "\"\"\"\n",
    "cc = ['l0_ya.npy', 'l1_yu.npy', 'l2_oi.npy', 'l3_yoi.npy',\n",
    "      'l4_yai.npy', 'l5_p.npy', 'l6_m.npy', 'l7_t.npy',\n",
    "      'l8_r.npy', 'l9_b.npy']\n",
    "# fig345, ax345 = plt.subplots(5,5)\n",
    "# test_letter = d[cc[0].split('.')[0]]\n",
    "# for i in range(5):\n",
    "# for j in range(5):\n",
    "# test_letter = d[cc[0].split('.')[0]].copy()\n",
    "# test_letter[i,j] = 1 if not test_letter[i,j] else 0\n",
    "# ax345[i,j].imshow(np.array(test_letter.copy()), cmap='jet')\n",
    "# for i in range(5):\n",
    "# for j in range(5):\n",
    "# print (5*i+j)\n",
    "\"\"\" 10 examples for the training, each example has 6*5 features, or 30 virtual reservoir nod\n",
    "\"\"\"\n",
    "X = np.zeros((25,30))\n",
    "num_letter = 0# between 0 and 9\n",
    "# test_letter = d[cc[0].split('.')[0]]\n",
    "fig345, ax345 = plt.subplots(5,5)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        test_letter = d[cc[num_letter].split('.')[0]].copy()\n",
    "        test_letter[i,j] = 1 if not test_letter[i,j] else 0\n",
    "        initial_state = np.random.random(1)\n",
    "        output = []\n",
    "        case_letter = np.array(test_letter.copy())\n",
    "        ax345[i,j].imshow(np.array(case_letter),cmap=plt.cm.Greens, clim=[-1,2])\n",
    "        for row in case_letter:\n",
    "            output.append(output_row(initial_state,row))\n",
    "        X[5*i+j,:] = np.concatenate(output)\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\" X --> Input.\n",
    "    w --> weights.\n",
    "    b --> bias.\"\"\"\n",
    "    # Predicting\n",
    "    z = X@w + b\n",
    "    y_hat = softmax(z)\n",
    "    # print (y_hat.shape)\n",
    "    # Returning the class with highest probability.\n",
    "    return np.argmax(y_hat, axis=1)\n",
    "    # return y_hat\n",
    "\n",
    "# for i in range(30)\n",
    "print ('prediction of the corresponding letter', num_letter, ':', predict(X, w, b))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9061750ffb1741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T02:05:43.632754Z",
     "start_time": "2024-12-23T02:05:42.974209Z"
    }
   },
   "source": [
    "def predict(X, w, b):\n",
    "    \"\"\" X --> Input.\n",
    "    w --> weights.\n",
    "    b --> bias.\"\"\"\n",
    "    # Predicting\n",
    "    z = X@w + b\n",
    "    y_hat = softmax(z)\n",
    "    # print (y_hat.shape)\n",
    "    # Returning the class with highest probability.\n",
    "    return np.argmax(y_hat, axis=1)\n",
    "\n",
    "\"\"\" test the 10 cases for making the confusion matrix\n",
    "\"\"\"\n",
    "X = np.zeros((25,30))\n",
    "confusion_matrix = np.zeros((10,10))\n",
    "\n",
    "for num_letter in range(10):# between 0 and 9\n",
    "    # test_letter = d[cc[0].split('.')[0]]\n",
    "    fig345, ax345 = plt.subplots(5,5)\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            test_letter = d[cc[num_letter].split('.')[0]].copy()\n",
    "            test_letter[i,j] = 1 if not test_letter[i,j] else 0\n",
    "            initial_state = np.random.random(1)\n",
    "            output = []\n",
    "            case_letter = np.array(test_letter.copy())\n",
    "            ax345[i,j].imshow(np.array(case_letter),cmap=plt.cm.Greens, clim=[-1,2])\n",
    "            for row in case_letter:\n",
    "                output.append(output_row(initial_state,row))\n",
    "            X[5*i+j,:] = np.concatenate(output)\n",
    "        predictions = predict(X, w, b)\n",
    "        print ('prediction of the corresponding letter', num_letter, ':', predictions)\n",
    "        for n_lett, prob in Counter(predictions).items():\n",
    "            confusion_matrix[num_letter, n_lett] = prob/25*100.\n",
    "            \n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec116760957a85",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
