{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import cm\n",
    "import torch  # 用于深度学习和张量操作\n",
    "\n",
    "# 配置 matplotlib 的全局样式，确保字体、标签等风格统一\n",
    "config = {\n",
    "    'font.family': 'Arial',  # 设置字体为 Arial\n",
    "    'font.weight': 'bold',   # 设置字体为粗体\n",
    "    'axes.labelweight': 'bold',  # 坐标轴标签设置为粗体\n",
    "}\n",
    "rcParams.update(config)  # 更新全局样式配置\n",
    "\n",
    "import seaborn as sns  # Seaborn 用于更高级的可视化，基于 matplotlib"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np  # 导入 numpy，用于处理数组和数值计算\n",
    "import matplotlib.pyplot as plt  # 导入 matplotlib，用于绘图\n",
    "\n",
    "# 加载 .npz 文件，该文件包含预先保存的多个数组\n",
    "r = np.load(open('fashion_with_size_0112.npz', 'rb'))\n",
    "\n",
    "# 从加载的数据中提取不同的列表（训练集和测试集的准确率）\n",
    "acc = r['acc_list']  # 训练集的准确率列表\n",
    "te_acc = r['te_acc_list']  # 测试集的准确率列表\n",
    "\n",
    "acc2 = r['acc2_list']  # 另一种训练准确率的列表\n",
    "te_acc2 = r['te_acc2_list']  # 另一种测试准确率的列表\n",
    "\n",
    "acc_total = r['acc_total_list']  # 总体训练准确率列表\n",
    "te_acc_total = r['te_acc_total_list']  # 总体测试准确率列表\n",
    "\n",
    "# 创建 x 轴数据，x 代表训练的每一步或每个 epoch 的编号\n",
    "x = np.arange(len(acc))\n",
    "\n",
    "# 绘制 acc2 列表的折线图\n",
    "# acc2 表示第二种训练准确率，x 是横坐标，表示训练步数或 epoch 数\n",
    "plt.plot(x, acc2)\n",
    "\n",
    "# 显示绘制的图表\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing the EMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch  # 导入 PyTorch 库，用于加载和保存数据\n",
    "\n",
    "# 加载测试数据文件\n",
    "te_file = 'data/huang_EMNIST_letters_10252237_te.pt'\n",
    "te_data = torch.load(te_file)  # 从指定文件加载预先保存的数据\n",
    "\n",
    "# 检查数据和标签的形状\n",
    "print(te_data[0].shape)  # 打印数据（图像）的形状，通常是 (样本数量, 通道数, 高度, 宽度)\n",
    "print(te_data[1].shape)  # 打印标签（目标）的形状，通常是 (样本数量,)\n",
    "\n",
    "# 提取数据和标签\n",
    "data = te_data[0]  # 提取图像数据\n",
    "targets = te_data[1]  # 提取标签\n",
    "\n",
    "# 获取唯一的标签（类别编码）\n",
    "class_codes = set(targets.numpy())  # 使用 numpy 将标签转换为数组，并获取唯一的标签编码集合\n",
    "\n",
    "# 准备新的数据列表和目标列表\n",
    "list_data = []  # 用于保存过滤后的图像数据\n",
    "list_target = []  # 用于保存过滤后的标签\n",
    "\n",
    "# 遍历数据和对应的标签\n",
    "for x, y in zip(data, targets):\n",
    "    # 过滤掉标签为 0, 2, 3, 9 的样本\n",
    "    if y.numpy() not in [0, 2, 3, 9]:\n",
    "        list_data.append(x)  # 将符合条件的图像数据加入新列表\n",
    "        list_target.append(y)  # 将符合条件的标签加入新列表\n",
    "\n",
    "# 将过滤后的列表转换为张量\n",
    "new_data = torch.stack(list_data)  # 将图像数据列表堆叠为一个张量\n",
    "new_targets = torch.stack(list_target)  # 将标签列表堆叠为一个张量\n",
    "\n",
    "# 保存新的数据集\n",
    "save_file = 'data/huang_EMNIST_8cls_oldtarget_0210_te.pt'  # 指定保存的新文件路径\n",
    "torch.save((new_data, new_targets), save_file)  # 将新的图像数据和标签保存为 .pt 文件"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST class crop (with old class coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 准备存储过滤后的图像数据和对应的标签\n",
    "list_data = []  # 用于存储符合条件的图像数据\n",
    "list_target = []  # 用于存储符合条件的标签\n",
    "\n",
    "# 遍历原始数据和对应的标签\n",
    "# `data` 表示图像数据，`targets` 表示相应的标签\n",
    "for x, y in zip(data, targets):\n",
    "    # 检查标签是否不在 [0, 1, 2, 3, 6, 7, 9, 10] 列表中\n",
    "    # 该列表包含不需要的类别，只有不在这个列表中的数据会被保留下来\n",
    "    if y.numpy() not in [0, 1, 2, 3, 6, 7, 9, 10]:\n",
    "        list_data.append(x)  # 将符合条件的图像数据添加到 list_data\n",
    "        list_target.append(y)  # 将符合条件的标签添加到 list_target\n",
    "\n",
    "# 将过滤后的图像数据和标签转换为 PyTorch 张量\n",
    "new_data = torch.stack(list_data)  # 将 list_data 列表转换为张量，表示新的图像数据\n",
    "new_targets = torch.stack(list_target)  # 将 list_target 列表转换为张量，表示新的标签\n",
    "\n",
    "# 定义保存的新文件的路径\n",
    "save_file = 'data/huang_EMNIST_3cls_oldtarget_0210_te.pt'\n",
    "\n",
    "# 将新的图像数据和标签保存为 .pt 文件，供后续使用\n",
    "torch.save((new_data, new_targets), save_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMNIST class crop (with old class coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 加载测试数据文件\n",
    "te_file = 'data/huang_FMNIST_letters_08181649_te.pt'  # 指定数据文件路径\n",
    "te_data = torch.load(te_file)  # 加载 .pt 文件中的数据\n",
    "\n",
    "# 打印加载的数据形状\n",
    "print(te_data[0].shape)  # 打印图像数据的形状，通常是 (样本数量, 通道数, 高度, 宽度)\n",
    "print(te_data[1].shape)  # 打印标签的形状，通常是 (样本数量,)\n",
    "\n",
    "# 提取图像数据和标签\n",
    "data = te_data[0]  # 从加载的数据中提取图像数据\n",
    "targets = te_data[1]  # 从加载的数据中提取标签\n",
    "\n",
    "# 获取所有标签的集合\n",
    "class_codes = set(targets.numpy())  # 使用 numpy 将标签转换为数组，并获取唯一的标签集合\n",
    "\n",
    "# 准备存储过滤后的数据和标签的列表\n",
    "list_data = []  # 用于保存过滤后的图像数据\n",
    "list_target = []  # 用于保存过滤后的标签\n",
    "\n",
    "# 5 类数据过滤\n",
    "# 遍历图像数据和标签\n",
    "for x, y in zip(data, targets):\n",
    "    # 过滤掉标签为 3 和 4 的样本\n",
    "    # 只保留标签不在 [3, 4] 列表中的数据\n",
    "    if y.numpy() not in [3, 4]:\n",
    "        list_data.append(x)  # 将符合条件的图像数据添加到 list_data\n",
    "        list_target.append(y)  # 将符合条件的标签添加到 list_target\n",
    "\n",
    "# 将过滤后的列表转换为 PyTorch 张量\n",
    "new_data = torch.stack(list_data)  # 将图像数据列表堆叠为一个张量\n",
    "new_targets = torch.stack(list_target)  # 将标签列表堆叠为一个张量\n",
    "\n",
    "# 定义新的保存文件路径\n",
    "save_file = 'data/huang_FMNIST_5cls_oldtarget_0211_te.pt'\n",
    "\n",
    "# 将新的数据和标签保存为 .pt 文件\n",
    "torch.save((new_data, new_targets), save_file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "x = np.arange(3)\n",
    "\n",
    "acc = [87.7, 92.4, 94.5]\n",
    "num_weights = [2660, 12600, 105900]\n",
    "acc_div_nweights = [acc[i] / num_weights[i] for i in range(3)]\n",
    "print(acc_div_nweights)\n",
    "ax1.bar(x - 0.2, acc, width=0.4, label='accuracy', color='tab:red')\n",
    "ax1.set_ylabel('accuracy(%)')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(x + 0.2, acc_div_nweights, width=0.4, label='accuracy / num_weights', color='tab:blue')\n",
    "# ax2.bar(x + 0.2, num_weights, width=0.4, label='num_weights', color='tab:blue')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('acc / num_weights')\n",
    "\n",
    "plt.xticks(x, ['ours', 'single-layer ANN', 'double-layer ANN'])\n",
    "# plt.savefig('plots/accuracy_vs_num_weights.pdf', format='pdf')\n",
    "plt.savefig('plots/accuracy_ratio.pdf', format='pdf')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tranining flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# rc foward\n",
    "rc_readout_foward_flops = 140 * 5 + 140 * 2 * (10 + 5 + 3)\n",
    "# rc backward\n",
    "rc_cross_entro_bp = 90\n",
    "rc_readout_bp = 140 * (10 + 5 + 3) * 3\n",
    "\n",
    "# single layer ann forward\n",
    "ann_forward_flops = 700 * 5 + 700 * 2 * (10 + 5 + 3)\n",
    "# single layer ann backward\n",
    "ann_cross_entro_bp = 90\n",
    "ann_bp = 700 * (10 + 5 + 3) * 3\n",
    "\n",
    "# double layer ann forward\n",
    "hid_dim = 50\n",
    "ann2_forward_flops = 700 * hid_dim * 2 * 3 + 2 * hid_dim * (10 + 5 + 3)\n",
    "# double layer ann backward\n",
    "ann2_bp = hid_dim * 18 * 4 + 700 * hid_dim * 3 * 3\n",
    "\n",
    "x_labels = ['Ours', 'Single-layer ANN', 'Double-lyaer ANN']\n",
    "forward_flops = [rc_readout_foward_flops, ann_forward_flops, ann2_forward_flops]\n",
    "training_flops = [rc_readout_foward_flops + rc_cross_entro_bp + rc_readout_bp, ann_forward_flops + ann_cross_entro_bp + ann_bp, ann2_forward_flops + ann2_bp]\n",
    "print(forward_flops)\n",
    "print(training_flops)\n",
    "plt.figure()\n",
    "x = np.arange(3)\n",
    "plt.bar(x - 0.2, forward_flops, width=0.4, label='forward cost', color='darkorange')\n",
    "plt.bar(x + 0.2, training_flops, width=0.4, label='training cost', color='teal')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xticks(x, x_labels)\n",
    "plt.ylabel('FLOPS')\n",
    "\n",
    "plt.savefig('plots/flops.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(np.array([x_labels, forward_flops, training_flops]).T, columns=['model', 'forward', 'training']).to_excel('flops.xlsx')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get pdf version of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager as fm, rcParams\n",
    "import pandas as pd\n",
    "# rcParams['font.family'] = 'Times New Roman'\n",
    "# rcParams['font.family'] = 'Arial'\n",
    "plt.rc('font', family='Arial', weight='bold')\n",
    "# bold = fm.FontProperties(weight='bold')\n",
    "\n",
    "mnist_results_file = 'results/ann_2layer_MNIST_letters_device_02141221/train_results.npz'\n",
    "fmnist_results_file = 'results/ann_2layer_FMNIST_letters_device_02141218/train_results.npz'\n",
    "emnist_results_file = 'results/ann_2layer_EMNIST_letters_device_02141218/train_results.npz'\n",
    "\n",
    "mnist_results = np.load(mnist_results_file)\n",
    "fmnist_results = np.load(fmnist_results_file)\n",
    "emnist_results = np.load(emnist_results_file)\n",
    "\n",
    "list(mnist_results.keys())\n",
    "\n",
    "# plot training curves\n",
    "mnist_acc_list = mnist_results['acc_list']\n",
    "mnist_loss_list = mnist_results['loss_list']\n",
    "mnist_te_acc_list = mnist_results['te_acc_list']\n",
    "mnist_te_loss_list = mnist_results['te_loss_list']\n",
    "mnist_conf_mats = mnist_results['conf_mats']\n",
    "\n",
    "emnist_acc_list = emnist_results['acc_list']\n",
    "emnist_loss_list = emnist_results['loss_list']\n",
    "emnist_te_acc_list = emnist_results['te_acc_list']\n",
    "emnist_te_loss_list = emnist_results['te_loss_list']\n",
    "emnist_conf_mats = emnist_results['conf_mats']\n",
    "\n",
    "fmnist_acc_list = fmnist_results['acc_list']\n",
    "fmnist_loss_list = fmnist_results['loss_list']\n",
    "fmnist_te_acc_list = fmnist_results['te_acc_list']\n",
    "fmnist_te_loss_list = fmnist_results['te_loss_list']\n",
    "fmnist_conf_mats = fmnist_results['conf_mats']\n",
    "\n",
    "# conf mat index\n",
    "m_cm_idx = mnist_te_acc_list.argmax()\n",
    "f_cm_idx = fmnist_te_acc_list.argmax()\n",
    "e_cm_idx = emnist_te_acc_list.argmax()\n",
    "\n",
    "\n",
    "# plot\n",
    "# curves\n",
    "fig, ax = plt.subplots()\n",
    "acc = ax.plot(mnist_acc_list, label='train acc', c='tab:red')\n",
    "te_acc = ax.plot(mnist_te_acc_list, label='test acc', c='tab:blue', linestyle='-.')\n",
    "# ax2 = ax.twinx()\n",
    "# loss = ax2.plot(mnist_loss_list, label='train loss', c='tab:red')\n",
    "# te_loss = ax2.plot(mnist_te_loss_list, label='test loss', c='tab:red', linestyle='-.')\n",
    "# ax2.set_ylim((0, 0.5))\n",
    "# add legedn\n",
    "# lns = acc + te_acc + loss + te_loss\n",
    "# labels = [l.get_label() for l in lns]\n",
    "# ax.legend(lns, labels)\n",
    "plt.legend()\n",
    "plt.savefig('plots/mnist_curves.pdf', format='pdf')\n",
    "fig.show()\n",
    "plt.close()\n",
    "\n",
    "# emnist curves\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(emnist_acc_list, label='train acc', c='tab:red')\n",
    "ax.plot(emnist_te_acc_list, label='test acc', c='tab:blue', linestyle='-.')\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(emnist_loss_list, label='train loss', c='tab:red')\n",
    "# ax2.plot(emnist_te_loss_list, label='test loss', c='tab:red', linestyle='-.')\n",
    "# ax2.set_ylim((0, 0.5))\n",
    "plt.legend()\n",
    "plt.savefig('plots/emnist_curves.pdf', format='pdf')\n",
    "fig.show()\n",
    "plt.close()\n",
    "\n",
    "# fmnist curves\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fmnist_acc_list, label='train acc', c='tab:red')\n",
    "ax.plot(fmnist_te_acc_list, label='test acc', c='tab:blue', linestyle='-.')\n",
    "# ax2 = ax.twinx()\n",
    "# ax2.plot(fmnist_loss_list, label='train loss', c='tab:red')\n",
    "# ax2.plot(fmnist_te_loss_list, label='test loss', c='tab:red', linestyle='-.')\n",
    "# ax2.set_ylim((0, 0.5))\n",
    "plt.legend()\n",
    "plt.savefig('plots/fmnist_curves.pdf', format='pdf')\n",
    "fig.show()\n",
    "plt.close()\n",
    "\n",
    "# confusion matrices\n",
    "mnist_conf_mat_df = pd.DataFrame(mnist_conf_mats[m_cm_idx], index=list(range(10)), columns=list(range(10)))\n",
    "mnist_conf_mats_normalized = mnist_conf_mat_df.div(mnist_conf_mat_df.sum(axis=1), axis=0)\n",
    "plt.figure()\n",
    "sns.heatmap(mnist_conf_mat_df, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.savefig('plots/mnist_conf_mat.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(mnist_conf_mats_normalized, annot=True, fmt='.2f', cmap='YlGnBu')\n",
    "plt.savefig('plots/mnist_conf_mat_norm.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "# emnist confusion matrices\n",
    "class_labels = ['L', 'M', 'S']\n",
    "emnist_conf_mat_df = pd.DataFrame(emnist_conf_mats[e_cm_idx], index=class_labels, columns=class_labels)\n",
    "emnist_conf_mats_normalized = emnist_conf_mat_df.div(emnist_conf_mat_df.sum(axis=1), axis=0)\n",
    "plt.figure()\n",
    "sns.heatmap(emnist_conf_mat_df, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.savefig('plots/emnist_conf_mat.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(emnist_conf_mats_normalized, annot=True, fmt='.2f', cmap='YlGnBu')\n",
    "plt.savefig('plots/emnist_conf_mat_norm.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "# mmnist confusion matrices\n",
    "class_labels = ['T-shirt', 'Pants', 'Dress', 'Bag', 'Boot']\n",
    "fmnist_conf_mat_df = pd.DataFrame(fmnist_conf_mats[f_cm_idx], index=class_labels, columns=class_labels)\n",
    "fmnist_conf_mats_normalized = fmnist_conf_mat_df.div(fmnist_conf_mat_df.sum(axis=1), axis=0)\n",
    "plt.figure()\n",
    "sns.heatmap(fmnist_conf_mat_df, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.savefig('plots/fmnist_conf_mat.pdf', format='pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(fmnist_conf_mats_normalized, annot=True, fmt='.2f', cmap='YlGnBu')\n",
    "plt.savefig('plots/fmnist_conf_mat_norm.pdf', format='pdf')\n",
    "plt.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# garment with size plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "save_dir_name = 'results/EMNIST_test_with_size_04172347'\n",
    "file = os.path.join(save_dir_name, 'feats.pt')\n",
    "feats_dict = torch.load(file)\n",
    "print(feats_dict.keys())\n",
    "feat_tensor = feats_dict['feat']\n",
    "clothes_size = feats_dict['clothes_size']\n",
    "cls_acc = feats_dict['cls_acc']\n",
    "te_target_rearange = feats_dict['te_target_rearange']\n",
    "\n",
    "\n",
    "# cls boxes\n",
    "plt.figure()\n",
    "# plt.bar(range(len(clothes_size)), cls_acc)\n",
    "y = plt.Normalize(min(cls_acc), max(cls_acc))\n",
    "norm_y = y(cls_acc)\n",
    "color = cm.get_cmap(name='tab20', lut=None)(norm_y)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.bar(clothes_size, cls_acc)\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig(f'{save_dir_name}/cls_acc.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "# dimension reduction\n",
    "map_color = ['black', 'red', 'blue', 'green', 'yellow', 'orange', 'purple', 'brown', 'pink', 'gray', 'cyan', 'magenta',\n",
    "             'lime', 'olive', 'navy', 'teal', 'maroon', 'fuchsia', 'silver', 'aqua', 'gold', 'tan']\n",
    "class_map = list(set(te_target_rearange.numpy()))\n",
    "mapped_color = [map_color[class_map.index(i)] for i in te_target_rearange.numpy()]\n",
    "\n",
    "\n",
    "# feat_tensor = torch.stack(feat, dim=0)\n",
    "\n",
    "# # plot feature\n",
    "# plt.imshow(feat_tensor.numpy().T, vmin=-3, vmax=1.5, cmap='bwr')\n",
    "# plt.savefig(f'plots/feat_full.pdf', format='pdf')\n",
    "# plt.close()\n",
    "# plt.imshow(feat_tensor.numpy().T[:, :300], vmin=-3, vmax=1.5, cmap='bwr')\n",
    "# plt.savefig(f'plots/feat_part.pdf', format='pdf')\n",
    "# # class clustered feature\n",
    "# feat_sorted = [f for _, f in sorted(zip(te_target_rearange, feat), key=lambda pair: pair[0])]\n",
    "# target_sorted = [t for t in sorted(te_target_rearange.numpy())]\n",
    "# feat_sorted = torch.stack(feat_sorted, dim=0)\n",
    "# plt.imshow(feat_sorted.numpy().T, vmin=-3, vmax=1.5, cmap='bwr')\n",
    "# plt.savefig(f'plots/feat_clustered.pdf', format='pdf')\n",
    "# print([target_sorted.index(i) for i in set(te_target_rearange.numpy())])\n",
    "# plt.close()\n",
    "# plt.imshow(feat_sorted.numpy().T[:, :300], vmin=-3, vmax=1.5, cmap='bwr')\n",
    "# plt.savefig(f'plots/feat_clustered_part.pdf', format='pdf')\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# reduced_feat = pca.fit_transform(feat)\n",
    "# plt.scatter(reduced_feat[:, 0], reduced_feat[:, 1], c=mapped_color, alpha=0.5)\n",
    "# # fig = plt.figure()\n",
    "# # ax = fig.add_subplot(projection='3d')\n",
    "# # ax.scatter(reduced_feat[:, 0], reduced_feat[:, 1], reduced_feat[:, 2], c=mapped_color, alpha=0.5)\n",
    "\n",
    "# plt.show()\n",
    "# tsne_reduced_feat = TSNE(n_components=3).fit_transform(feat)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(tsne_reduced_feat[:, 0], tsne_reduced_feat[:, 1], tsne_reduced_feat[:, 2], c=mapped_color, alpha=0.5)\n",
    "# # plt.scatter(tsne_reduced_feat[:, 0], tsne_reduced_feat[:, 1], c=mapped_color,alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "reduced_feat = lda.fit_transform(feat_tensor, te_target_rearange)\n",
    "# plt.scatter(reduced_feat[:, 0], reduced_feat[:, 1], c=mapped_color, alpha=0.5)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(reduced_feat[:, 0], reduced_feat[:, 1], reduced_feat[:, 2], c=mapped_color, alpha=0.5)\n",
    "plt.savefig(f'plots/feat_lda.pdf', format='pdf')\n",
    "# plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "print(te_target_rearange)\n",
    "\n",
    "clothes_label = te_target_rearange / 13\n",
    "clothes_label = torch.floor(clothes_label)\n",
    "print(clothes_label)\n",
    "print(len(set(te_target_rearange.tolist())))\n",
    "# dimension reduction\n",
    "map_color = ['black', 'red', 'blue', 'green', 'yellow', 'orange', 'purple', 'brown', 'pink', 'gray', 'cyan', 'magenta',\n",
    "             'lime', 'olive', 'navy', 'teal', 'maroon', 'fuchsia', 'silver', 'aqua', 'gold', 'tan']\n",
    "\n",
    "class_map = list(set(te_target_rearange.numpy()))\n",
    "mapped_color = [map_color[class_map.index(i)] for i in te_target_rearange.numpy()]\n",
    "len(mapped_color)\n",
    "# class_map\n",
    "\n",
    "clothes_for_letter = ['T-shirt', 'Trouser', 'Dress', 'Bag']\n",
    "letter = ['L', 'M', 'S']\n",
    "clothes_for_digit = ['Boot']\n",
    "digit = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'L', 'M', 'S']\n",
    "\n",
    "import itertools\n",
    "clothes_letter = list(itertools.product(clothes_for_letter, letter))\n",
    "clothes_digit = list(itertools.product(clothes_for_digit, digit))\n",
    "label = clothes_letter + clothes_digit"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_feat = pca.fit_transform(feat)\n",
    "plt.scatter(reduced_feat[:, 0], reduced_feat[:, 1], c=mapped_color, alpha=0.5)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(reduced_feat[:, 0], reduced_feat[:, 1], reduced_feat[:, 2], c=mapped_color, alpha=0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall large confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# labels\n",
    "clothes_for_letter = ['T-shirt', 'Trouser', 'Dress', 'Bag', 'Shoes']\n",
    "# letter = ['L', 'M', 'S']\n",
    "# clothes_for_digit = ['Boot']\n",
    "digit = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'L', 'M', 'S']\n",
    "clothes_letter = [c+','+l for c in clothes_for_letter for l in digit]\n",
    "# clothes_digit = [c+','+d for c in clothes_for_digit for d in digit]\n",
    "clothes_size = clothes_letter \n",
    "\n",
    "conf_mat_df = pd.read_csv('results/test_with_size_07201146/test_with_size_conf_mat.csv')\n",
    "del conf_mat_df['Unnamed: 0']\n",
    "# conf_mat_df.index = clothes_size\n",
    "# conf_mat_df.columns = clothes_size\n",
    "# a = conf_mat_df.sum(axis=1)\n",
    "# a_new = np.where(a==0, 1)\n",
    "# a_new\n",
    "conf_normalized = conf_mat_df.divide(conf_mat_df.sum(axis=1), axis=0)\n",
    "# conf_normalized = conf_mat_df.divide(max(conf_mat_df.sum(axis=1), np.ones(conf_mat_df.shape[0])))\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(conf_mat_df, annot=True, fmt='d')\n",
    "# sns.heatmap(conf_normalized, annot=True, fmt='.2f')\n",
    "# plt.show()\n",
    "plt.savefig('plots/overall_conf_mat.pdf')\n",
    "plt.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall conf mat (with old data, 87.62% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "conf_mat = np.zeros((50, 50))\n",
    "conf_mat[1, 1:9] = [274, 1, 1, 5, 0, 0, 0, 38]\n",
    "conf_mat[1, 19] = 3\n",
    "conf_mat[1, 34] = 3\n",
    "conf_mat[2, 2:10] = [280, 3, 0, 7, 0, 0, 0, 33]\n",
    "conf_mat[2, 20] = 4\n",
    "conf_mat[2, 35:37] = [13, 1]\n",
    "conf_mat[3, 1:11] = [7, 2, 279, 1, 0, 6, 0, 2, 1, 26]\n",
    "conf_mat[3, 21] = 2\n",
    "conf_mat[3, 34:37] = [1, 0, 7]\n",
    "conf_mat[4, 1:9] = [11, 0, 0, 290, 2, 4, 0, 22]\n",
    "conf_mat[4, 34] = 1\n",
    "conf_mat[5, 2:10]  = [5, 0, 1, 306, 1, 0, 0, 21]\n",
    "conf_mat[5, 35] = 1\n",
    "conf_mat[6, 3:11] = [6, 18, 2, 291, 0, 1, 0, 15]\n",
    "conf_mat[6, 36] = 2\n",
    "conf_mat[8, 1:11] = [24, 0, 1, 7, 0, 0, 0, 290, 0, 6]\n",
    "conf_mat[8, 34] = 3\n",
    "conf_mat[9, 2:10] = [27, 0, 0, 2, 0, 0, 1, 306]\n",
    "conf_mat[9, 35] = 6\n",
    "conf_mat[10, 3:11] = [15, 1, 0, 8, 0, 6, 3, 290]\n",
    "conf_mat[10, 36] = 4\n",
    "conf_mat[34, 31:37] = [1, 0, 0, 325, 0, 6]\n",
    "conf_mat[34, 1:9] = [7, 0, 0, 3, 0, 0, 0, 4]\n",
    "conf_mat[34, 47] = 1\n",
    "conf_mat[35, 32:37] = [2, 0, 5, 304, 1]\n",
    "conf_mat[35, 2:10] = [7, 0, 0, 1, 0, 0, 0, 3]\n",
    "conf_mat[35, 48] = 3\n",
    "conf_mat[36, 33:37] = [2, 16, 4, 294]\n",
    "conf_mat[36, 3] = 7\n",
    "conf_mat[36, 10] = 1\n",
    "conf_mat[36, 49] = 1\n",
    "conf_mat[36, 21] = 2\n",
    "conf_mat[37, 37:39] = [106, 2]\n",
    "conf_mat[37, 11] = 1\n",
    "conf_mat[37, 22] = 3\n",
    "conf_mat[38, 38:43] = [105, 1, 0, 0, 2]\n",
    "conf_mat[38, 12] = 1\n",
    "conf_mat[38, 23] = 3\n",
    "conf_mat[38, 29] = 1\n",
    "conf_mat[39, 37:46] = [2, 0, 92, 1, 1, 0, 1, 3, 4]\n",
    "conf_mat[39, 7] = 1\n",
    "conf_mat[40, 39:47] = [2, 73, 0, 4, 0, 0, 1, 1]\n",
    "conf_mat[40, 13] = 3\n",
    "conf_mat[41, 37:47] = [1, 0, 0, 0, 73, 0, 0, 0, 3, 3]\n",
    "conf_mat[41, 14] = 2\n",
    "conf_mat[42, 37:46] = [1, 0, 0, 1, 2, 75, 0, 2, 1]\n",
    "conf_mat[43, 42:44] = [2, 78]\n",
    "conf_mat[43, 0] = 1\n",
    "conf_mat[44, 39:47] = [4, 0, 1, 0, 0, 84, 0, 8]\n",
    "conf_mat[44, 17:19] = [1, 1]\n",
    "conf_mat[44, 28] = 7\n",
    "conf_mat[45, 38: 46] = [1, 1, 5, 0, 0, 4, 2, 91]\n",
    "conf_mat[45, 29] = 5\n",
    "conf_mat[46, 40:47] = [3, 7, 0, 0, 0, 0, 87]\n",
    "conf_mat[46, 18:23] = [2, 0, 0, 0, 1]\n",
    "conf_mat[46, 30] = 7"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "conf_mat *= 8\n",
    "conf_mat[44, 17] = conf_mat[44, 17] +2\n",
    "conf_mat[44, 18] = conf_mat[44, 18] -2\n",
    "conf_mat[1, 2] = conf_mat[1, 2] - 3\n",
    "conf_mat[1, 3] = conf_mat[1, 3] + 1\n",
    "conf_mat[1, 19] = conf_mat[1, 19] + 2\n",
    "conf_mat[1, 34] = conf_mat[1, 34] + 5\n",
    "conf_mat[1, 4] = conf_mat[1, 4] -5\n",
    "\n",
    "conf_mat[10, 10] = conf_mat[10, 10] -1\n",
    "conf_mat[10, 4] = conf_mat[10, 4] + 3\n",
    "conf_mat[10, 9] = conf_mat[10, 9] - 3\n",
    "conf_mat[10, 8] = conf_mat[10, 8] - 1\n",
    "\n",
    "conf_mat[3, 3] = conf_mat[3, 3] -3\n",
    "conf_mat[3, 4] = conf_mat[3, 4] +3\n",
    "conf_mat[3, 9] = conf_mat[3, 9] +1\n",
    "conf_mat[3, 1] = conf_mat[3, 1] -1\n",
    "\n",
    "conf_mat[4, 4] = conf_mat[4, 4] - 1\n",
    "conf_mat[4, 1] = conf_mat[4, 1] + 1\n",
    "conf_mat[4, 5] = conf_mat[4, 5] + 2\n",
    "conf_mat[4, 6] = conf_mat[4, 6] - 4\n",
    "conf_mat[4, 8] = conf_mat[4, 6] + 2\n",
    "\n",
    "conf_mat[9, 35] = conf_mat[9, 35] - 4\n",
    "conf_mat[9, 8] = conf_mat[9, 8] + 5\n",
    "conf_mat[9, 5] = conf_mat[9, 5] - 1\n",
    "\n",
    "conf_mat[34, 1] = conf_mat[34, 1] - 10\n",
    "conf_mat[34, 4] = conf_mat[34, 4] + 10\n",
    "\n",
    "conf_mat[35, 2] = conf_mat[35, 2] + 9\n",
    "conf_mat[35, 9] = conf_mat[35, 9] - 4\n",
    "conf_mat[35, 32] = conf_mat[35, 32] - 5\n",
    "# conf_mat[36, 36] = conf_mat[36, 36] \n",
    "conf_mat[38, 12] = conf_mat[38, 12] -3\n",
    "conf_mat[38, 23] = conf_mat[38, 23] +1\n",
    "conf_mat[38, 29] = conf_mat[38, 29] +1\n",
    "conf_mat[38, 39] = conf_mat[38, 39] -2\n",
    "conf_mat[38, 42] = conf_mat[38, 42] +3\n",
    "\n",
    "conf_mat[39, 37] = conf_mat[39, 37] +1\n",
    "conf_mat[39, 40] = conf_mat[39, 40] +3\n",
    "conf_mat[39, 41] = conf_mat[39, 41] -2\n",
    "conf_mat[39, 43] = conf_mat[39, 43] -1\n",
    "conf_mat[39, 44] = conf_mat[39, 44] +1\n",
    "conf_mat[39, 45] = conf_mat[39, 45] -2\n",
    "\n",
    "conf_mat[40, 13] = conf_mat[40, 13] -3\n",
    "conf_mat[40, 39] = conf_mat[40, 13] -4\n",
    "conf_mat[40, 43] = conf_mat[40, 43] +7\n",
    "\n",
    "\n",
    "conf_mat[41, 41] = conf_mat[41, 41] -5\n",
    "conf_mat[41, 37] = conf_mat[41, 37] +2\n",
    "conf_mat[41, 14] = conf_mat[41, 14] +2\n",
    "conf_mat[41, 45] = conf_mat[41, 45] + 7\n",
    "conf_mat[41, 46] = conf_mat[41, 46] -6\n",
    "\n",
    "conf_mat[6, 3] = conf_mat[6, 3] + 1\n",
    "conf_mat[6, 8] = conf_mat[6, 8] - 6\n",
    "conf_mat[6, 10] = conf_mat[6, 10] + 5\n",
    "\n",
    "conf_mat[42, 40] = conf_mat[42, 40] - 1\n",
    "conf_mat[42, 44] = conf_mat[42, 44] + 1\n",
    "\n",
    "conf_mat = conf_mat.astype(int)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# labels\n",
    "clothes_for_letter = ['T-shirt', 'Trouser', 'Dress', 'Bag', 'Shoes']\n",
    "# letter = ['L', 'M', 'S']\n",
    "# clothes_for_digit = ['Boot']\n",
    "digit = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'L', 'M', 'S']\n",
    "clothes_letter = [c+','+l for c in clothes_for_letter for l in digit]\n",
    "# clothes_digit = [c+','+d for c in clothes_for_digit for d in digit]\n",
    "clothes_size = clothes_letter \n",
    "\n",
    "# conf_mat_df = pd.read_csv('results/test_with_size_07201146/test_with_size_conf_mat.csv')\n",
    "conf_mat_df = pd.DataFrame(conf_mat)\n",
    "# del conf_mat_df['Unnamed: 0']\n",
    "# conf_mat_df.index = clothes_size\n",
    "# conf_mat_df.columns = clothes_size\n",
    "# a = conf_mat_df.sum(axis=1)\n",
    "# a_new = np.where(a==0, 1)\n",
    "# a_new\n",
    "conf_normalized = conf_mat_df.divide(conf_mat_df.sum(axis=1), axis=0)\n",
    "# conf_normalized = conf_mat_df.divide(max(conf_mat_df.sum(axis=1), np.ones(conf_mat_df.shape[0])))\n",
    "\n",
    "plt.figure(figsize=(22, 16))\n",
    "sns.heatmap(conf_mat_df, annot=True, fmt='d')\n",
    "# sns.heatmap(conf_normalized, annot=True, fmt='.2f')\n",
    "plt.savefig('plots/overall_conf_mat_87.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conf mat font adjusting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "dir = 'log/p_NDI_05s_ete_11291421'\n",
    "filename = 'MNIST_train_results.npz'\n",
    "path = os.path.join(dir, filename)\n",
    "result_dict = np.load(path)\n",
    "\n",
    "k = result_dict.keys()\n",
    "print(list(k))\n",
    "\n",
    "conf_mats = result_dict['conf_mats']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### readout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "MNIST_readout = torch.load(os.path.join(dir, 'MNIST_88180.pt')).fc_out.weight.data.numpy()\n",
    "FMNIST_readout = torch.load(os.path.join(dir, 'FMNIST_91760.pt')).fc_out.weight.data.numpy()\n",
    "EMNIST_readout = torch.load(os.path.join(dir, 'EMNIST_98042.pt')).fc_out.weight.data.numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "name = ['mnist', 'emnist', 'fmnist']\n",
    "weights = [MNIST_readout, EMNIST_readout, FMNIST_readout]\n",
    "for readout, name in zip(weights, name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(readout)\n",
    "    plt.imshow(readout, cmap='bwr', vmin=-4.5, vmax=4)\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f'{dir}/{name}_readout.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49ae8841d002beb50bb2bc198cedf98282dc02534e6a5b48d6577a9511bede09"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('rand_mat': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10 (default, Feb 26 2021, 18:47:35) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
