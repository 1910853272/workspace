{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1加载必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.9605e-08,  8.0234e-02])\n"
     ]
    }
   ],
   "source": [
    "#定义晶体管参数\n",
    "Pmax=501\n",
    "Gmax=1\n",
    "Gmin=0\n",
    "o0=0.01 #c2c 引入器件误差\n",
    "def G(x):\n",
    "  return (1-np.exp(-x/100))/0.9933\n",
    "def G_1(x):\n",
    "  return -np.log(1-x*0.9933)*100\n",
    "def wnew(w,dw):    \n",
    "  #Wq=torch.round(w*Pmax)/Pmax\n",
    "  Gq=(w-1)/2*(Gmax-Gmin)+Gmax\n",
    "  P=torch.round(G_1(Gq))\n",
    "  dp=torch.round(dw/2*Pmax)\n",
    "  Gnew=G(P+dp)\n",
    "  y=(Gnew-Gmin)/(Gmax-Gmin)*2-1\n",
    "  return y\n",
    "def wwnew(w,dw):\n",
    "  Gq=(w-1)/2*(Gmax-Gmin)+Gmax\n",
    "  P=(G_1(Gq))\n",
    "  dp=(dw/2*Pmax)\n",
    "  Gnew=G(P+dp)\n",
    "  y=(Gnew-Gmin)/(Gmax-Gmin)*2-1\n",
    " \n",
    "  \n",
    "  return y\n",
    "\n",
    "#晶体管权重更新函数\n",
    "a=torch.tensor([0,0.08])\n",
    "b=torch.tensor([0,0.0001])\n",
    "\n",
    "print(wwnew(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2定义超参数\n",
    "BATCH_SIZE =128 # 每批处理的数据\n",
    "DEVICE = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")#\n",
    "EPOCHS = 20 #训练数据集的轮次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3构建pipeline，对图像做处理\n",
    "pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),#将图片转换成tensor\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#正则化：降低模型复杂度\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4下载，加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "#下载数据集\n",
    "train_set = datasets.MNIST(\"data\",train=True,download=True,transform=pipeline)\n",
    "\n",
    "test_set = datasets.MNIST(\"data\",train=False,download=True,transform=pipeline)\n",
    "#加载数据集\n",
    "train_loader =DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_loader= DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 插入代码，显示MNIST中图片\n",
    "with open(\"./data/MNIST/raw/train-images-idx3-ubyte\",\"rb\") as f:\n",
    "    file=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 24, 24, 24, 294, 310, 373, 38, 358, 597, 583, 295, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 54, 148, 340, 368, 595, 595, 595, 595, 595, 549, 370, 595, 578, 405, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 568, 595, 595, 595, 595, 595, 595, 595, 595, 593, 147, 130, 130, 86, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 537, 595, 595, 595, 595, 595, 408, 386, 583, 577, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 342, 263, 595, 595, 517, 17, 0, 67, 340, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 1, 340, 595, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 313, 595, 400, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 400, 595, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 577, 549, 352, 264, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 576, 595, 595, 281, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 390, 595, 595, 336, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 147, 594, 595, 391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 585, 595, 585, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 304, 387, 595, 595, 519, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 328, 553, 595, 595, 595, 592, 386, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 276, 545, 595, 595, 595, 595, 513, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 102, 531, 595, 595, 595, 595, 408, 129, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 369, 537, 595, 595, 595, 595, 405, 128, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 370, 550, 595, 595, 595, 595, 580, 307, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 310, 595, 595, 595, 530, 309, 306, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 345, 595, 345, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 72, 568, 594, 594, 594, 567, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 84, 551, 595, 594, 569, 563, 594, 87, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 96, 548, 594, 595, 594, 514, 132, 594, 595, 290, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 355, 594, 594, 594, 595, 594, 594, 150, 393, 595, 359, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 568, 595, 595, 400, 276, 595, 552, 71, 121, 597, 360, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 72, 568, 594, 594, 377, 18, 117, 289, 33, 0, 0, 595, 579, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 56, 357, 595, 563, 520, 132, 0, 0, 0, 0, 0, 0, 595, 594, 357, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 376, 594, 576, 113, 25, 40, 0, 0, 0, 0, 0, 0, 595, 594, 405, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87, 594, 594, 99, 0, 0, 0, 0, 0, 0, 0, 0, 0, 595, 594, 405, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 408, 595, 400, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 597, 595, 406, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 118, 582, 594, 274, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 595, 594, 328, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 594, 560, 37, 0, 0, 0, 0, 0, 0, 0, 0, 7, 309, 595, 390, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 594, 547, 0, 0, 0, 0, 0, 0, 0, 0, 7, 305, 594, 549, 113, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 594, 325, 0, 0, 0, 0, 0, 0, 0, 72, 357, 594, 371, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 134, 595, 549, 0, 0, 0, 0, 0, 0, 276, 568, 595, 354, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 594, 585, 326, 72, 41, 133, 376, 549, 595, 547, 359, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 133, 594, 594, 594, 553, 533, 594, 594, 594, 406, 304, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 409, 594, 594, 595, 594, 594, 563, 325, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 296, 594, 595, 594, 321, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "image1 = [int(str(item).encode(\"ascii\"),16) for item in file[16:16+784]]\n",
    "print(image1)\n",
    "image2 = [int(str(item).encode(\"ascii\"),16) for item in file[16+784:16+784*2]]\n",
    "print(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image1_np =np.array(image1,dtype=np.uint8).reshape(28,28,1)\n",
    "print(image1_np.shape)\n",
    "cv2.imwrite(\"digit1.jpg\",image1_np)\n",
    "image2_np =np.array(image2,dtype=np.uint8).reshape(28,28,1)\n",
    "print(image2_np.shape)\n",
    "cv2.imwrite(\"digit2.jpg\",image2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5 构建网络模型\n",
    "class Digit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) #第一个卷积层（1：输入的灰度图的通道，10：输出通道，5：卷积层Kernel）\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) #第二个卷积层（10：输入通道，20：输出通道，3：卷积层Kernel）\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) #第一个全连接层（20*10*10：输入通道，500：输出通道）\n",
    "        self.fc2 = nn.Linear(500, 10) #第二个全连接层（500：输入通道，10：输出通道【0~9】）\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0) # batch_size\n",
    "        x = self.conv1(x) # 输入：batch*1*28*28，输出：batch*10*24*24 (28-5+1=24)\n",
    "        x = F.relu(x) #激活函数，保持shape不变，输出：batch*10*24*24\n",
    "        x = F.max_pool2d(x, 2, 2) #池化层 输入：batch*10*24*24， 输出：batch*10*12*12\n",
    "        \n",
    "        x = self.conv2(x) # 输入：batch*10*12*12，输出：batch*20*10*10 （12-3+1=10）\n",
    "        x = F.relu(x) # \n",
    "        \n",
    "        x = x.view(input_size, -1) # 拉平， -1：自动计算维度  20*10*10=2000\n",
    "        \n",
    "        x = self.fc1(x) # 输入：batch*2000 输出：batch*500\n",
    "        x = F.relu(x) # 激活， 保持shape不变\n",
    "        \n",
    "        x = self.fc2(x) # 输入：batch*500，输出：batch*10\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1) #计算分类后，每个数字0~9的概率\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义优化器\n",
    "\n",
    "class MyOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr):\n",
    "        self.lr = lr\n",
    "        super(MyOptimizer, self).__init__(params, {})\n",
    "\n",
    "    def step(self, closure=False):\t\n",
    "        \n",
    "        for param_group in self.param_groups:\n",
    "            params = param_group['params']\n",
    "            # 从param_group中拿出参数\n",
    "            for param in params:\n",
    "                # 循环更新每一个参数的值\n",
    "                #param.data = param.data - self.lr * param.grad #纯软件\n",
    "                param.data = wwnew(param.data,- self.lr*param.grad) #晶体管模拟\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6定义优化器\n",
    "model = Digit().to(DEVICE)\n",
    "#optimizer = optim.SGD(model.parameters(),0.1)\n",
    "optimizer = MyOptimizer(model.parameters(),0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7定义训练方法\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    # 模型训练\n",
    "    model.train()\n",
    "    for batch_index, (img, target) in enumerate(train_loader):\n",
    "        # 将数据部署到DEVICE上去\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        # 梯度初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        # 训练后的结果\n",
    "        output = model(img)\n",
    "        # 计算loss\n",
    "        loss = F.cross_entropy(output, target) #cross_entropy适合多分类问题，将计算结果与真实值对比\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 参数优化\n",
    "        optimizer.step() # 用step方法更新参数\n",
    "      \n",
    "    \n",
    "        # 每隔3000张图片打印一次loss\n",
    "        if batch_index % 3000 == 0:\n",
    "            print(\"Train Epoch : {} \\t Loss : {:.8f}\".format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 定义测试方法\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    # 模型验证\n",
    "    model.eval()\n",
    "    # 初始化正确率\n",
    "    correct = 0.0\n",
    "    # 初始化测试loss\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad(): # 测试时不会计算梯度，也不会进行反向传播\n",
    "        for img, target in test_loader:\n",
    "            # 部署到DEVICE上\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            # 测试数据\n",
    "            output = model(img)\n",
    "            # 计算测试损失\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            # 找到概率最大下标\n",
    "            pred = output.max(1, keepdim=True)[1] #值，索引 \n",
    "                # pred = output.argmax(dim=1)\n",
    "                # pred = torch.max(output, dim=1)\n",
    "            # 累计正确的值\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy =100 * correct / len(test_loader.dataset)\n",
    "        print(\"Test --Average loss : {:.4f}, Accuracy : {:.3f}\\n\".format(\n",
    "            test_loss, test_accuracy))\n",
    "    return(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 \t Loss : 2.30289531\n",
      "Test --Average loss : 0.0017, Accuracy : 93.180\n",
      "\n",
      "93.18\n",
      "Train Epoch : 2 \t Loss : 0.15405929\n",
      "Test --Average loss : 0.0007, Accuracy : 97.140\n",
      "\n",
      "97.14\n",
      "Train Epoch : 3 \t Loss : 0.12957472\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6r/4q_j6wtd76n8rs8wn3pf7qr40000gn/T/ipykernel_12795/3320147447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mt_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/4q_j6wtd76n8rs8wn3pf7qr40000gn/T/ipykernel_12795/524126934.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 参数优化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 用step方法更新参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/4q_j6wtd76n8rs8wn3pf7qr40000gn/T/ipykernel_12795/793621638.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;31m# 循环更新每一个参数的值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m#param.data = param.data - self.lr * param.grad #纯软件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwwnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#晶体管模拟\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/4q_j6wtd76n8rs8wn3pf7qr40000gn/T/ipykernel_12795/3145822352.py\u001b[0m in \u001b[0;36mwwnew\u001b[0;34m(w, dw)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwwnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mGq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGmax\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mGmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mGmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mdp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mPmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mGnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6r/4q_j6wtd76n8rs8wn3pf7qr40000gn/T/ipykernel_12795/3145822352.py\u001b[0m in \u001b[0;36mG_1\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0.9933\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mG_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.9933\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m#Wq=torch.round(w*Pmax)/Pmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, array)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;31m# `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             return handle_torch_function(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9 调用方法7、8\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "plt.figure(figsize=(10, 10))  # 设置图像大小\n",
    "plt.axis([0, 10, 0, 100])\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_model(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    t_a=test_model(model, DEVICE, test_loader)\n",
    "    print(t_a)\n",
    "    plt.scatter(epoch, t_a,color='r', marker='o')\n",
    "    scale = range(100)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
